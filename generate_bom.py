import json, re, urllib.parse
from pathlib import Path

# --- Configuration (Constantes en cache local) ---
CFG = {
    "ext": ".stl", "out": "BOM.md", "json": "print_settings.json", "root": "stl",
    "repo": "https://github.com", "branch": "main",
    "fields": ["perimetres", "couches_dessus", "couches_dessous", "remplissage", 
               "motif_remplissage", "longueur_ancre", "longueur_max_ancre"]
}

# Regex compilÃ© une seule fois
RE_QTY = re.compile(r'(?:x|qty)(\d+)', re.IGNORECASE)

def generate_bom():
    # 1. Mise en cache des variables pour Ã©viter les lookups CFG['...']
    ROOT_DIR = Path(CFG["root"])
    JSON_PATH = Path(CFG["json"])
    FIELDS = CFG["fields"]
    EMPTY_INFO = {f: None for f in FIELDS} # Template rÃ©utilisÃ©
    
    if not ROOT_DIR.exists(): return

    # 2. Chargement JSON ultra-rapide
    try:
        data_json = json.loads(JSON_PATH.read_text(encoding="utf-8")) if JSON_PATH.exists() else {}
    except:
        data_json = {}

    md = ["# ğŸ“‹ Nomenclature", "\n> `ğŸŸ¢` ConfigurÃ© | `ğŸ”´` Incomplet\n"]
    
    # PrÃ©-calculer la base URL pour limiter les concatÃ©nations
    url_template = f"{CFG['repo']}/{{}}/{CFG['branch']}/"

    # 3. Traitement avec un seul parcours disque (rglob) par catÃ©gorie
    for cat in sorted((d for d in ROOT_DIR.iterdir() if d.is_dir()), key=lambda x: x.name.lower()):
        md.extend([f"## ğŸ“¦ {cat.name.upper()}", 
                   "| Statut | PiÃ¨ce | QtÃ© | PÃ©rimÃ¨tre | Couches | Remplissage | Ancre / Max | Voir | STL |",
                   "|:---:|:---|:---:|:---:|:---:|:---:|:---:|:---:|:---:|"])

        # On rÃ©cupÃ¨re tout d'un coup, triÃ© par nom de fichier (Natural Sort simulÃ© par lower)
        # On utilise une liste de comprÃ©hension pour la vitesse
        for item in sorted(cat.rglob(f"*{CFG['ext']}"), key=lambda x: x.name.lower()):
            path_str = item.as_posix()
            
            # RÃ©cupÃ©ration / Initialisation optimisÃ©e (get + update)
            info = data_json.get(path_str)
            if info is None:
                info = data_json[path_str] = EMPTY_INFO.copy()

            # Analyse rapide : on s'arrÃªte au premier None/vide rencontrÃ©
            ok = 'ğŸŸ¢' if all(info.get(f) for f in FIELDS) else 'ğŸ”´'
            
            # Extraction QtÃ© (search est plus rapide que findall pour un seul rÃ©sultat)
            m = RE_QTY.search(item.name)
            qty = m.group(1) if m else "1"

            # Formatage : calcul de profondeur relatif Ã  la catÃ©gorie
            depth = len(item.relative_to(cat).parts) - 1
            indent = f"{'&nbsp;' * (4 * depth)}ğŸ“„ "
            
            # Encodage URL (opÃ©ration la plus lourde, isolÃ©e ici)
            encoded_path = urllib.parse.quote(path_str)
            full_url = url_template + encoded_path

            md.append(
                f"| {ok} | {indent}<samp>{item.name}</samp> | `x{qty}` | "
                f"`{info['perimetres'] or '-'}` | "
                f"`{info['couches_dessus'] or '-'}â†‘ {info['couches_dessous'] or '-'}â†“` | "
                f"`{info['remplissage'] or '-'} ({info['motif_remplissage'] or '-'})` | "
                f"`{info['longueur_ancre'] or '-'} â‡¥ {info['longueur_max_ancre'] or '-'}` | "
                f"[<samp>ğŸ‘ï¸ VUE</samp>]({full_url.format('blob')}) | "
                f"[<samp>ğŸ“¥ STL</samp>]({full_url.format('raw')}) |"
            )
        
        md.append("\n---\n")

    # 4. Ã‰criture atomique (rÃ©duit les risques de corruption de fichier)
    JSON_PATH.write_text(json.dumps(data_json, indent=4, ensure_ascii=False), encoding="utf-8")
    Path(CFG["out"]).write_text("\n".join(md), encoding="utf-8")

if __name__ == "__main__":
    generate_bom()
